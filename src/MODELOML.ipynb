{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>0-9</th>\n",
       "      <th>19-Oct</th>\n",
       "      <th>20-29</th>\n",
       "      <th>30-39</th>\n",
       "      <th>40-49</th>\n",
       "      <th>50-59</th>\n",
       "      <th>60-69</th>\n",
       "      <th>70-79</th>\n",
       "      <th>80+</th>\n",
       "      <th>...</th>\n",
       "      <th>Unemployed_2018</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Population Aged 60+</th>\n",
       "      <th>county_pop2018_18 and older</th>\n",
       "      <th>anycondition_number</th>\n",
       "      <th>Obesity_number</th>\n",
       "      <th>COPD_number</th>\n",
       "      <th>diabetes_number</th>\n",
       "      <th>CKD_number</th>\n",
       "      <th>Heart disease_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.229763</td>\n",
       "      <td>-0.225393</td>\n",
       "      <td>-0.231350</td>\n",
       "      <td>-0.229775</td>\n",
       "      <td>-0.223780</td>\n",
       "      <td>-0.228216</td>\n",
       "      <td>-0.227030</td>\n",
       "      <td>-0.231375</td>\n",
       "      <td>-0.232151</td>\n",
       "      <td>-0.231665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177629</td>\n",
       "      <td>-0.228413</td>\n",
       "      <td>-0.227824</td>\n",
       "      <td>-0.230288</td>\n",
       "      <td>-0.231574</td>\n",
       "      <td>-0.230636</td>\n",
       "      <td>-0.222477</td>\n",
       "      <td>-0.215940</td>\n",
       "      <td>-0.216950</td>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.161280</td>\n",
       "      <td>-0.179851</td>\n",
       "      <td>-0.181109</td>\n",
       "      <td>-0.188375</td>\n",
       "      <td>-0.176225</td>\n",
       "      <td>-0.163303</td>\n",
       "      <td>-0.139120</td>\n",
       "      <td>-0.112664</td>\n",
       "      <td>-0.124916</td>\n",
       "      <td>-0.099555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132117</td>\n",
       "      <td>-0.153492</td>\n",
       "      <td>-0.106368</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>-0.146243</td>\n",
       "      <td>-0.158219</td>\n",
       "      <td>-0.117073</td>\n",
       "      <td>-0.135257</td>\n",
       "      <td>-0.135212</td>\n",
       "      <td>3796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.198764</td>\n",
       "      <td>-0.209983</td>\n",
       "      <td>-0.195009</td>\n",
       "      <td>-0.168470</td>\n",
       "      <td>-0.194740</td>\n",
       "      <td>-0.193726</td>\n",
       "      <td>-0.199360</td>\n",
       "      <td>-0.218215</td>\n",
       "      <td>-0.220562</td>\n",
       "      <td>-0.204552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193902</td>\n",
       "      <td>-0.196750</td>\n",
       "      <td>-0.215126</td>\n",
       "      <td>-0.195032</td>\n",
       "      <td>-0.193279</td>\n",
       "      <td>-0.201734</td>\n",
       "      <td>-0.194220</td>\n",
       "      <td>-0.188714</td>\n",
       "      <td>-0.204982</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.048115</td>\n",
       "      <td>-0.049041</td>\n",
       "      <td>-0.029705</td>\n",
       "      <td>-0.067671</td>\n",
       "      <td>-0.062335</td>\n",
       "      <td>-0.044847</td>\n",
       "      <td>-0.033104</td>\n",
       "      <td>-0.044844</td>\n",
       "      <td>-0.036279</td>\n",
       "      <td>-0.057310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081974</td>\n",
       "      <td>-0.048519</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.051170</td>\n",
       "      <td>-0.016632</td>\n",
       "      <td>-0.007673</td>\n",
       "      <td>-0.021363</td>\n",
       "      <td>-0.057561</td>\n",
       "      <td>-0.055748</td>\n",
       "      <td>5484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070012</td>\n",
       "      <td>0.073864</td>\n",
       "      <td>0.080526</td>\n",
       "      <td>0.038603</td>\n",
       "      <td>0.025430</td>\n",
       "      <td>0.048850</td>\n",
       "      <td>0.079829</td>\n",
       "      <td>0.119807</td>\n",
       "      <td>0.116625</td>\n",
       "      <td>0.139396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071894</td>\n",
       "      <td>0.076228</td>\n",
       "      <td>0.135093</td>\n",
       "      <td>0.067785</td>\n",
       "      <td>0.140471</td>\n",
       "      <td>0.156960</td>\n",
       "      <td>0.232009</td>\n",
       "      <td>0.100319</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>8686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TOT_POP       0-9    19-Oct     20-29     30-39     40-49     50-59  \\\n",
       "0 -0.229763 -0.225393 -0.231350 -0.229775 -0.223780 -0.228216 -0.227030   \n",
       "1 -0.161280 -0.179851 -0.181109 -0.188375 -0.176225 -0.163303 -0.139120   \n",
       "2 -0.198764 -0.209983 -0.195009 -0.168470 -0.194740 -0.193726 -0.199360   \n",
       "3 -0.048115 -0.049041 -0.029705 -0.067671 -0.062335 -0.044847 -0.033104   \n",
       "4  0.070012  0.073864  0.080526  0.038603  0.025430  0.048850  0.079829   \n",
       "\n",
       "      60-69     70-79       80+  ...  Unemployed_2018  Total Population  \\\n",
       "0 -0.231375 -0.232151 -0.231665  ...        -0.177629         -0.228413   \n",
       "1 -0.112664 -0.124916 -0.099555  ...        -0.132117         -0.153492   \n",
       "2 -0.218215 -0.220562 -0.204552  ...        -0.193902         -0.196750   \n",
       "3 -0.044844 -0.036279 -0.057310  ...        -0.081974         -0.048519   \n",
       "4  0.119807  0.116625  0.139396  ...         0.071894          0.076228   \n",
       "\n",
       "   Population Aged 60+  county_pop2018_18 and older  anycondition_number  \\\n",
       "0            -0.227824                    -0.230288            -0.231574   \n",
       "1            -0.106368                    -0.155864            -0.146243   \n",
       "2            -0.215126                    -0.195032            -0.193279   \n",
       "3            -0.042488                    -0.051170            -0.016632   \n",
       "4             0.135093                     0.067785             0.140471   \n",
       "\n",
       "   Obesity_number  COPD_number  diabetes_number  CKD_number  \\\n",
       "0       -0.230636    -0.222477        -0.215940   -0.216950   \n",
       "1       -0.158219    -0.117073        -0.135257   -0.135212   \n",
       "2       -0.201734    -0.194220        -0.188714   -0.204982   \n",
       "3       -0.007673    -0.021363        -0.057561   -0.055748   \n",
       "4        0.156960     0.232009         0.100319    0.108446   \n",
       "\n",
       "   Heart disease_number  \n",
       "0                  2072  \n",
       "1                  3796  \n",
       "2                  2222  \n",
       "3                  5484  \n",
       "4                  8686  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"../data/processed/clean_train.csv\")\n",
    "test_data = pd.read_csv(\"../data/processed/clean_test.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop([\"Heart disease_number\"], axis = 1)\n",
    "y_train = train_data[\"Heart disease_number\"]\n",
    "X_test = test_data.drop([\"Heart disease_number\"], axis = 1)\n",
    "y_test = test_data[\"Heart disease_number\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REALIZAMOS LA REGRESION LINEAL Y LUEGO LO VOLVERMOS A REALIZAR PERO CON LASSO O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()  # Puedes probar 'sag', 'saga', 'newton-cg', entre otros\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercep (a): [-0.29199193 -0.29228981 -0.29087321 ... -2.51403598 -2.72542544\n",
      " -2.48500056]\n",
      "Coefficients: [[-0.0766244  -0.0720725  -0.07864317 ... -0.12225713 -0.08661343\n",
      "  -0.08742658]\n",
      " [-0.0767593  -0.07267905 -0.07924032 ... -0.12226184 -0.08649653\n",
      "  -0.0871205 ]\n",
      " [-0.07646082 -0.07206106 -0.0786423  ... -0.12198876 -0.08634995\n",
      "  -0.08712162]\n",
      " ...\n",
      " [ 0.21387876  0.30621557  0.38289332 ...  0.39386631 -0.20522189\n",
      "   0.38283041]\n",
      " [ 0.23180464  0.13697314  0.10521427 ...  0.31601655 -0.04187198\n",
      "   0.30095988]\n",
      " [ 0.24401686  0.14992442  0.19179744 ...  0.06545478  0.48467143\n",
      "   0.32567169]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Intercep (a): {model.intercept_}\")\n",
    "print(f\"Coefficients: {model.coef_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1072,  8689,  1072,  8506,  8689,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  3376,  1072,  8689,  1072, 50635,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072, 93262,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  8689,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  8689,  1072,  1072,  1072,\n",
       "        1072,  1072,  8506,  1072,  1072, 39011,  1072,  1072,  1072,\n",
       "        8506,  1072, 44330,  1072,  1072,  1072,  8689,  1072,  1072,\n",
       "        8689,  1072,  1072,  1072,  1072,  1072, 23641,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072, 43089,  1072,  1072,  1072,  1072,\n",
       "        3376,  8689,  1072,  1072,  1072, 43410,  1072,  1072,  7128,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  8506,\n",
       "        1072, 76128,  8689,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        7128, 23641,  1072,  8506, 25091,  3376,  1072, 16376,  1072,\n",
       "        1072,  8689,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        3376,  1072,  8689,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072, 23641,  1072,  1072,  1072,  1072, 43410,  1072,\n",
       "        1072,  1072,  1072,  1072,  3376,  1072,  1072, 74849,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  7128,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  7128, 32863,  1072,  1072,\n",
       "        8506,  1072,  1072,  3376,  1072,  1072,  3376,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  8689,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  8689,  8506, 67657,  1072,  3376,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  8689,\n",
       "        1072,  1072,  1072,  8689,  1072,  1072,  1072,  1072,  8689,\n",
       "        1072,  8506,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  7128,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072, 62563,  1072,  1072,  1072,\n",
       "        1072,  1072, 52383,  1072,  1072,  8506,  1072,  3376,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  3376,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072, 30044,  8689,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  8689,  1072,  3376,  1072,  1072,  8689,  1072, 22248,\n",
       "        8689,  1072,  1072,  3376,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072, 30044,  3376,  1072,  1072,  1072,  1072,  1072,\n",
       "        8689,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  8506,  1072,  1072,  1072,  8506,  1072,  3376, 16450,\n",
       "        1072,  1072,  1072,  3376,  1072,  3376,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        3376,  1072,  8689,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072, 23641, 23641,  1072,\n",
       "        1072,  1072,  3376,  1072,  1072, 62563,  3376,  1072,  1072,\n",
       "        8689,  1072,  1072,  3376, 23641,  8506,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072, 23641,\n",
       "        1072,  1072,  1072,  1072,  3376,  1072,  1072,  1072,  1072,\n",
       "        1072, 83688,  1072,  3376,  1072,  1072,  1072,  8506,  1072,\n",
       "        3376,  1072,  8689,  1072,  3376,  1072, 62563,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072, 23641, 33226,  1072,\n",
       "        1072,  1072, 39011,  1072,  3376,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  8689,  1072,  1072,  3376,\n",
       "        1072, 30044,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        3376,  1072,  1072,  8689,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  8689,  1072,\n",
       "        1072,  1072,  8689,  1072,  8506,  8506,  1072,  1072,  1072,\n",
       "       23641,  1072,  1072, 47805,  1072,  1072, 23641,  8506,  1072,\n",
       "        1072,  1072,  1072,  3376,  1072,  1072,  1072,  1072,  1072,\n",
       "        3376,  1072,  1072,  1072,  1072,  8506,  1072,  1072,  1072,\n",
       "        1072,  1072, 22248,  1072,  3376,  7128,  1072,  1072,  1072,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072, 23641, 23641,\n",
       "        1448,  1072,  1072, 23641,  1072,  8689,  1072,  1072,  3376,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  3376,  1072,\n",
       "        3376, 37762,  1072,  1072, 78363,  1072,  1072,  7128, 42090,\n",
       "        3376,  1072,  1072,  1072,  1072,  1072,  1072,  1072, 16376,\n",
       "        1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,  1072,\n",
       "        1072,  1072,  3376,  1072,  8689,  3376,  1072,  1072, 23641,\n",
       "       23641,  1072,  1072,  1072,  1072,  1072,  1072,  8689,  1072,\n",
       "        8689,  1072,  1072, 16376,  1072,  8506,  3376,  1072,  1072,\n",
       "        8689,  1072,  1072,  1072,  1072,  8506,  1072,  1072,  1072,\n",
       "        8506,  1072,  1072,  1072,  1072,  3376,  1072])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 14582044.729299363\n",
      "R2 Score: 0.8333965694159089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAMOS OPTIMIZARLO CON LASSO Y RIDGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIMIZACION DE LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [    0.          3286.84313335 -2020.99300521  -350.13854493\n",
      "  -360.14325365  1518.6566098      0.          -539.42186017\n",
      "  3287.64743156     0.          1639.98991771 -2783.86746984\n",
      "  -372.59981296 -1270.0821705     37.49704426    69.2009904\n",
      " -2192.06108453 -2590.57169648  2085.18007952   598.22800523\n",
      "  -160.15647344  3014.4279729   6971.59713669  2562.94293396\n",
      "  4434.59544271]\n",
      "R2 score: 0.9980411985319951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.345e+08, tolerance: 7.097e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha = 1.0\n",
    "random_seed = 42\n",
    "lasso_model = Lasso(alpha=alpha, random_state=random_seed, max_iter=2000)\n",
    "# Entrenamos el modelo\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos el rendimiento del modelo en los datos de prueba\n",
    "score = lasso_model.score(X_test, y_test)\n",
    "print(\"Coefficients:\", lasso_model.coef_)\n",
    "print(\"R2 score:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CON LA OPTIMIZACION LASSO HEMOS CONSEGUIDO MEJOR NUESTRO R2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAMOS A PROBAR CON RIDGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [  199.40934584  3248.16419173 -2411.5109503   -432.32318692\n",
      " -1066.44408681  1170.94249468  -371.87835938   -18.57564009\n",
      "  3296.8536971    431.71921776  1459.48819654   199.40934585\n",
      "   -14.89151874 -1198.70078935   510.78129761   617.20658017\n",
      " -1957.75963396 -4561.6364846    908.50268693   412.15764438\n",
      "   -29.78926226  2845.84534276  6570.87222415  2597.77081377\n",
      "  4457.87525732]\n",
      "R2 score: 0.9980275227961202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alpha = 1.0\n",
    "random_seed = 42\n",
    "\n",
    "ridge_model = Ridge(alpha = 1.0)\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Evaluamos el rendimiento del modelo en los datos de prueba\n",
    "score2 = ridge_model.score(X_test, y_test)\n",
    "print(\"Coefficients:\", ridge_model.coef_)\n",
    "print(\"R2 score:\", score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVAMOS QUE TAMBIEN REALIZA UNA BUENA ESTIMACION PERO ES LIGERAMENTE MEJOR LA OPTIMIZACION CON LASSO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
